{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import re\n",
    "import csv\n",
    "\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofdata = [] # this is my list that contains every single node/tag in every xml file that I downloaded\n",
    "\n",
    "\n",
    "def parse_xml(folder):\n",
    "\n",
    "    for x in glob.glob(folder + '/*.xml'):\n",
    "        with open(x, 'rt', encoding='ISO-8859-1') as infile:\n",
    "            tree = ET.parse(infile)\n",
    "            for node in tree.iter():\n",
    "                if node.tag == 'rootTag':\n",
    "                    listofdata.append('rootTag')\n",
    "                elif node.tag == 'AwardEffectiveDate':\n",
    "                    listofdata.append(node.text)\n",
    "                elif node.tag == 'AwardExpirationDate':\n",
    "                    listofdata.append(node.text)\n",
    "                elif node.tag == 'AwardAmount':\n",
    "                    listofdata.append(node.text)\n",
    "                elif node.tag == 'LongName':\n",
    "                    listofdata.append(node.text)\n",
    "                elif node.tag == 'AbstractNarration':\n",
    "                    listofdata.append(node.text)\n",
    "                elif node.tag == 'MinAmdLetterDate':\n",
    "                    listofdata.append(node.text)\n",
    "                elif node.tag == 'MaxAmdLetterDate':\n",
    "                    listofdata.append(node.text)\n",
    "                elif node.tag == 'StartDate':\n",
    "                    listofdata.append(node.text)\n",
    "                elif node.tag == 'Name':\n",
    "                    listofdata.append(node.text)\n",
    "                elif node.tag == 'StateName':\n",
    "                    listofdata.append(node.text)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            \n",
    "    return listofdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = ['2013_NSF', '2014_NSF', '2015_NSF', '2016_NSF', '2017_NSF', '2018_NSF']\n",
    "\n",
    "for d in dir_list:\n",
    "    extract_xml(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('listofdata.pickle', 'wb') as f:\n",
    "    pickle.dump(listofdata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofdata=pd.read_pickle('listofdata.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step is to separate the list into list of lists, with each list belonging to one single xml file\n",
    "roottag = re.compile(r'rootTag')\n",
    "rtlist=[]\n",
    "for i,v in enumerate(listofdata):\n",
    "    if re.match(roottag, str(v)):\n",
    "        rtlist.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofrecords = []\n",
    "ind = 1\n",
    "for r in rtlist:\n",
    "    single_record = listofdata[r:rtlist[ind+1]]\n",
    "    listofrecords.append(single_record)\n",
    "    if ind < len(rtlist)-2:\n",
    "        ind += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('listofrecords.pickle', 'wb') as f:\n",
    "    pickle.dump(listofrecords, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofrecords = pd.read_pickle('listofrecords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(listofrecords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to convert timestamp columns into pandas datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AwardEffdt']= pd.to_datetime(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AwardExp_dt']= pd.to_datetime(df[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Award_amt']= df[3].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Min_amend_dt']= pd.to_datetime(df[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Max_amend_dt']= pd.to_datetime(df[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Grant_length']=df['AwardExp_dt']-df['AwardEffdt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amend_length'] = df['Max_amend_dt']-df['Min_amend_dt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I need to convert the 'grant length' and 'Amended days' column into the number of days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_days=[]\n",
    "for i,x in enumerate(df['Grant_length']):\n",
    "    gl_days.append(df['Grant_length'][i].days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gl_days']= gl_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gl_days'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_days = []\n",
    "for i,x in enumerate(df['Amend_length']):\n",
    "    am_days.append(df['Amend_length'][i].days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Am_days']=am_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of words in the abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_words = []\n",
    "for x in range(0, len(df)):\n",
    "    try:\n",
    "        abs_words.append(len(df[5][x]))\n",
    "     #   abs_words.append(len(award_data2['Abstract'][x]))\n",
    "    except:\n",
    "        abs_words.append('0')\n",
    "     #   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Abstract_length']=abs_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Abstract_length']=df['Abstract_length'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df.pickle', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dummy variable for the 'Directorate' column (Biology, Math, Physics, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.get_dummies(df[4])\n",
    "Z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.join(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_dummy.pickle', 'wb') as f:\n",
    "    pickle.dump(df2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df_dummy.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add State data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stdata = pd.read_csv('statelist.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(df,stdata, on='Index', sort=False, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_dept_sts.pickle', 'wb') as f:\n",
    "    pickle.dump(df2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_pickle('df_dept_sts.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add University/Institution data (had to clean this up because this field was spread out among 5 different columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univdata = pd.read_csv('combined_univ.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df2,univdata, on='Index', sort=False,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_dept_sts_univ.pickle', 'wb') as f:\n",
    "    pickle.dump(df3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df_dept_sts_univ.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add University/Institution Ranking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings=pd.read_csv('inst_RD_ranking.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.merge(df,rankings, on='Index', sort=False,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.drop('Institution_y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.drop([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,\n",
    "                24,25,26,27,28,29,30,31,32,33,34,35,36], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_cleaned_data.pickle', 'wb') as f:\n",
    "    pickle.dump(df4, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('final_cleaned_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modelready_data.pickle', 'wb') as f:\n",
    "    pickle.dump(df4, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('modelready_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AwardEffdt', 'AwardExp_dt', 'Award_amt', 'Min_amend_dt',\n",
       "       'Max_amend_dt', 'Grant_length', 'Amend_length', 'Gl_days', 'Am_days',\n",
       "       'Abstract_length', 'Direct For Biological Sciences',\n",
       "       'Direct For Computer & Info Scie & Enginr',\n",
       "       'Direct For Education and Human Resources',\n",
       "       'Direct For Mathematical & Physical Scien',\n",
       "       'Direct For Social, Behav & Economic Scie',\n",
       "       'Directorate For Engineering', 'Directorate For Geosciences',\n",
       "       'Directorate for Geosciences', 'National Coordination Office',\n",
       "       'Natl Nanotechnology Coordinating Office',\n",
       "       'Office Of Information & Resource Mgmt', 'Office Of Polar Programs',\n",
       "       'Office Of The Director',\n",
       "       'Office of Budget, Finance, & Award Management', 'Index', 'State',\n",
       "       'Institution_x', '2016_RD_exp_rank', '2016_RD_perc',\n",
       "       'Rank_gradstudents_x', 'Rank_doctorates', 'Rank_gradstudents_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('Index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dummy variables for University/Institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = pd.get_dummies(df['Institution_x'])\n",
    "U = U.drop(['Direct For Biological Sciences','Direct For Computer & Info Scie & Enginr',\n",
    "       'Direct For Education and Human Resources','Direct For Mathematical & Physical Scien',\n",
    "       'Direct For Social, Behav & Economic Scie', 'Directorate For Engineering', 'Directorate For Geosciences',\n",
    "       'Office Of Information & Resource Mgmt', 'Office Of Polar Programs','Office Of The Director',\n",
    "            'Alaska Pacific University','University of Alaska Anchorage Campus',\n",
    "            'University of Alaska Fairbanks Campus',  'University of Alaska Southeast Juneau Campus'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18F GSA</th>\n",
       "      <th>2B Technologies, Inc</th>\n",
       "      <th>2W iTech LLC</th>\n",
       "      <th>3D Biotek, LLC</th>\n",
       "      <th>3DEO, Inc.</th>\n",
       "      <th>3Derm Systems, Inc.</th>\n",
       "      <th>3I Diagnostics, Inc.</th>\n",
       "      <th>4 D Technology Corporation</th>\n",
       "      <th>4-Web Spine Inc.</th>\n",
       "      <th>490 BioTech Inc</th>\n",
       "      <th>...</th>\n",
       "      <th>schultzhaus Zachary</th>\n",
       "      <th>selfarray</th>\n",
       "      <th>shark wheel</th>\n",
       "      <th>unspun, Inc.</th>\n",
       "      <th>vonSternberg Nicholas C</th>\n",
       "      <th>whitaker                melissa        r</th>\n",
       "      <th>wondervisions</th>\n",
       "      <th>yearONE LLC</th>\n",
       "      <th>zGlue, Inc.</th>\n",
       "      <th>zeroK NanoTech Corporation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   18F GSA  2B Technologies, Inc  2W iTech LLC  3D Biotek, LLC  3DEO, Inc.  \\\n",
       "0        0                     0             0               0           0   \n",
       "1        0                     0             0               0           0   \n",
       "2        0                     0             0               0           0   \n",
       "3        0                     0             0               0           0   \n",
       "4        0                     0             0               0           0   \n",
       "\n",
       "   3Derm Systems, Inc.  3I Diagnostics, Inc.  4 D Technology Corporation  \\\n",
       "0                    0                     0                           0   \n",
       "1                    0                     0                           0   \n",
       "2                    0                     0                           0   \n",
       "3                    0                     0                           0   \n",
       "4                    0                     0                           0   \n",
       "\n",
       "   4-Web Spine Inc.  490 BioTech Inc             ...              \\\n",
       "0                 0                0             ...               \n",
       "1                 0                0             ...               \n",
       "2                 0                0             ...               \n",
       "3                 0                0             ...               \n",
       "4                 0                0             ...               \n",
       "\n",
       "   schultzhaus Zachary  selfarray  shark wheel  unspun, Inc.  \\\n",
       "0                    0          0            0             0   \n",
       "1                    0          0            0             0   \n",
       "2                    0          0            0             0   \n",
       "3                    0          0            0             0   \n",
       "4                    0          0            0             0   \n",
       "\n",
       "   vonSternberg Nicholas C  whitaker                melissa        r  \\\n",
       "0                        0                                         0   \n",
       "1                        0                                         0   \n",
       "2                        0                                         0   \n",
       "3                        0                                         0   \n",
       "4                        0                                         0   \n",
       "\n",
       "   wondervisions  yearONE LLC  zGlue, Inc.  zeroK NanoTech Corporation  \n",
       "0              0            0            0                           0  \n",
       "1              0            0            0                           0  \n",
       "2              0            0            0                           0  \n",
       "3              0            0            0                           0  \n",
       "4              0            0            0                           0  \n",
       "\n",
       "[5 rows x 5350 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.join(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dummy variables for State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alabama</th>\n",
       "      <th>Alaska</th>\n",
       "      <th>Alaska Pacific University</th>\n",
       "      <th>Arizona</th>\n",
       "      <th>Arkansas</th>\n",
       "      <th>California</th>\n",
       "      <th>Colorado</th>\n",
       "      <th>Connecticut</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>District of Columbia</th>\n",
       "      <th>...</th>\n",
       "      <th>University of Alaska Fairbanks Campus</th>\n",
       "      <th>University of Alaska Southeast Juneau Campus</th>\n",
       "      <th>Utah</th>\n",
       "      <th>Vermont</th>\n",
       "      <th>Virgin Islands</th>\n",
       "      <th>Virginia</th>\n",
       "      <th>Washington</th>\n",
       "      <th>West Virginia</th>\n",
       "      <th>Wisconsin</th>\n",
       "      <th>Wyoming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alabama  Alaska  Alaska Pacific University  Arizona  Arkansas  California  \\\n",
       "0        0       0                          0        0         0           0   \n",
       "1        0       0                          0        0         0           0   \n",
       "2        0       0                          0        0         0           0   \n",
       "3        0       0                          0        0         0           0   \n",
       "4        0       0                          0        0         0           0   \n",
       "\n",
       "   Colorado  Connecticut  Delaware  District of Columbia   ...     \\\n",
       "0         0            0         0                     0   ...      \n",
       "1         0            0         0                     0   ...      \n",
       "2         0            0         0                     0   ...      \n",
       "3         0            0         0                     0   ...      \n",
       "4         0            0         0                     0   ...      \n",
       "\n",
       "   University of Alaska Fairbanks Campus  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   University of Alaska Southeast Juneau Campus  Utah  Vermont  \\\n",
       "0                                             0     0        0   \n",
       "1                                             0     0        0   \n",
       "2                                             0     0        0   \n",
       "3                                             0     0        0   \n",
       "4                                             0     0        0   \n",
       "\n",
       "   Virgin Islands  Virginia  Washington  West Virginia  Wisconsin  Wyoming  \n",
       "0               0         0           0              0          0        0  \n",
       "1               0         0           0              0          0        0  \n",
       "2               0         0           0              0          0        0  \n",
       "3               0         0           0              0          0        0  \n",
       "4               0         0           0              0          0        0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = pd.get_dummies(df['State'])\n",
    "S.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2.join(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('finalized_data.pickle', 'wb') as f:\n",
    "    pickle.dump(df3, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
